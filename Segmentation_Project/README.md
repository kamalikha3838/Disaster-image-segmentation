This project demonstrates how deep learning can be used to segment disaster-affected regions from satellite images. The workflow includes:

Loading and preprocessing satellite images

Applying U-Net architecture for segmentation

Training, validating, and evaluating the model

Generating prediction masks

Comparing model output with ground truth

Below is a high-level preview of the project structure:

ğŸ“ Disaster Image Segmentation
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ images/        # Input satellite images
â”‚   â”œâ”€â”€ masks/         # Annotation masks
â”‚
â”œâ”€â”€ models/
â”‚   â””â”€â”€ unet_model.h5  # Saved trained model
â”‚
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ training.ipynb # Main model training notebook
â”‚
â””â”€â”€ README.md

